import os
from dotenv import load_dotenv
from tavily import TavilyClient
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI

load_dotenv()

# --- AYARLAR ---
def load_keywords(file_path="keywords.txt"):
    """Anahtar kelimeleri txt dosyasÄ±ndan yÃ¼kler."""
    keywords = []
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                
                if line and not line.startswith("#"):
                    keywords.append(line.lower())
        print(f"âœ… {len(keywords)} anahtar kelime yÃ¼klendi.")
    except FileNotFoundError:
        print(f"âš ï¸ {file_path} bulunamadÄ±! VarsayÄ±lan kelimeler kullanÄ±lÄ±yor.")
        keywords = ["alerji", "alerjen", "astÄ±m", "kaÅŸÄ±ntÄ±", "besin", "polen", "ilaÃ§", "test", "saÄŸlÄ±k"]
    return keywords

ALLOWED_KEYWORDS = load_keywords()
chat_history = []
# Modeller

llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)
embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
tavily = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
db = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)

def get_text_content(ai_message):
    """Modelden gelen cevabÄ±n liste veya string olma durumunu gÃ¼venle Ã§Ã¶zer."""
    content = ai_message.content
    if isinstance(content, list):
        # Liste gelirse ilk elemanÄ±n iÃ§indeki 'text' anahtarÄ±nÄ± al
        return content[0].get('text', '')
    return str(content)

print("âœ… SÃœPER ASÄ°STAN Ã‡EVRÄ°MÄ°Ã‡Ä°! (HafÄ±za + CanlÄ± Arama + Filtre) (Ã‡Ä±kmak iÃ§in 'q' veya 'exit' yazÄ±n)")

while True:
    user_input = input("\nSiz: ")
    if user_input.lower() in ['q', 'exit']: break
    if not user_input.strip(): continue

    # --- 1. KATMAN: ANAHTAR KELÄ°ME KONTROLÃœ ---
    if not any(word in user_input.lower() for word in ALLOWED_KEYWORDS):
        print("Bot: ÃœzgÃ¼nÃ¼m, sadece uzmanlÄ±k alanÄ±m (Alerji/SaÄŸlÄ±k) ile ilgili sorularÄ± yanÄ±tlayabilirim. ğŸ˜Š")
        continue

    # --- 2. KATMAN: KONU ANALÄ°ZÄ° (Gatekeeper) ---
    check_prompt = f"Bu soru saÄŸlÄ±k/alerji ile mi ilgili? EVET veya HAYIR olarak cevap ver. Soru: {user_input}"
    raw_check = llm.invoke(check_prompt)
    check_text = get_text_content(raw_check).upper()

    if "EVET" not in check_text:
        print("Bot: Bu konu uzmanlÄ±k alanÄ±mÄ±n dÄ±ÅŸÄ±nda kalÄ±yor. BaÅŸka bir saÄŸlÄ±k sorunuz var mÄ±?")
        continue

    print("ğŸ” Bilgi harmanlanÄ±yor...")

    # --- 3. KATMAN: HAFIZA VE ARAÅTIRMA ---
    local_docs = db.similarity_search(user_input, k=3)
    sources = list(set([d.metadata.get("source", "Dosya") for d in local_docs]))
    local_context = "\n".join([d.page_content for d in local_docs])

    try:
        # Web aramasÄ±nÄ± daha spesifik hale getirmek iÃ§in 'medical' ekliyoruz
        web_res = tavily.search(query=f"{user_input} medical allergy", search_depth="advanced")
        web_context = "\n".join([r['content'] for r in web_res['results']])
    except Exception as e:
        web_context = "Web aramasÄ± yapÄ±lamadÄ±."

    # --- 4. KATMAN: CEVAP OLUÅTURMA ---
    # GeÃ§miÅŸteki son 2 mesajÄ± hafÄ±za olarak veriyoruz
    final_prompt = f"""
    Sen uzman bir alerji asistanÄ±sÄ±n.
    
    SOHBET GEÃ‡MÄ°ÅÄ°: {chat_history[-4:]}
    YEREL KAYNAKLAR: {local_context}
    WEB BÄ°LGÄ°SÄ°: {web_context}
    
    SORU: {user_input}
    
    Talimat: Bilgileri birleÅŸtir, tÄ±bbi terimleri aÃ§Ä±kla ve dÃ¼rÃ¼st ol. Kaynaklarda yoksa uydurma.
    """

    final_res = llm.invoke(final_prompt)
    response_text = get_text_content(final_res)
    
    print(f"\nBot: {response_text}")
    print(f"\nğŸ“ YararlanÄ±lan Kaynaklar: {', '.join(sources)}")
    
    # HafÄ±zayÄ± gÃ¼ncelle
    chat_history.append(f"KullanÄ±cÄ±: {user_input}")
    chat_history.append(f"Bot: {response_text}")
